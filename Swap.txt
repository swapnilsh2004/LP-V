#!/usr/bin/env python
# coding: utf-8

import os
import re
import cv2
import numpy as np
import pytesseract
from pdf2image import convert_from_path

# ---------------------------------------------------------------------------
# 1. CONFIGURATION
# ---------------------------------------------------------------------------

# Update this path if Tesseract is not in your PATH
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# Languages
LANG_DEV = "hin+mar"
LANG_ENG = "eng"

# --- Configurations ---
# General: Automatic page segmentation
CONFIG_GENERAL  = r'--oem 3 --psm 6'

# Specific: When we crop a specific script, we tell Tesseract EXACTLY what to look for
CONFIG_LINE_DEV = r'--oem 3 --psm 6' 
CONFIG_LINE_ENG = r'--oem 3 --psm 6'

# Numbers/Dates: Added punctuation (.,-/@) to whitelist so dates/URLs don't break
CONFIG_DIGITS   = r'--oem 3 --psm 7 -c tessedit_char_whitelist=0123456789,.:-/@'

# Regex to detect Devanagari (Hindi/Marathi) characters
DEV_RGX = re.compile(r'[\u0900-\u097F]')


# ---------------------------------------------------------------------------
# 2. IMAGE PRE-PROCESSING
# ---------------------------------------------------------------------------

def preprocess_image(pil_image):
    """
    Converts to Grayscale.
    CRITICAL: We DO NOT use binary thresholding (black/white) because it 
    corrupts stylized fonts (like the 'M' in Mahotsav).
    """
    img = np.array(pil_image)
    
    # Handle RGBA/RGB
    if len(img.shape) == 2:
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    elif img.shape[2] == 4:
        img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)
        
    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    
    # Mild smoothing to remove scanner noise
    denoised = cv2.GaussianBlur(gray, (3, 3), 0)
    
    return denoised


# ---------------------------------------------------------------------------
# 3. HELPER FUNCTIONS
# ---------------------------------------------------------------------------

def is_numeric_like(word):
    # Checks if word is mostly numbers (allows for currency/math symbols)
    return any(c.isdigit() for c in word)

def fix_text_general(text):
    """
    Simple cleanup. 
    We REMOVED the regex that was deleting spaces between words and numbers.
    """
    text = re.sub(r'\s+([?.!,"])', r'\1', text)  # Remove space before punctuation
    text = re.sub(r'\s+', ' ', text)             # Collapse multiple spaces
    return text.strip()

def remove_duplicate_lines(lines):
    seen = set()
    unique = []
    for line in lines:
        norm = line.strip()
        if norm and norm not in seen:
            seen.add(norm)
            unique.append(line)
    return unique


# ---------------------------------------------------------------------------
# 4. CORE "SPLIT & STITCH" LOGIC
# ---------------------------------------------------------------------------

def ocr_crop(crop, script, coarse_text):
    """
    Runs OCR on a specific crop with the CORRECT language setting.
    """
    # 1. Hindi/Marathi Span
    if script == "DEV":
        return pytesseract.image_to_string(crop, lang=LANG_DEV, config=CONFIG_LINE_DEV)
    
    # 2. English Span
    if script == "ENG":
        return pytesseract.image_to_string(crop, lang=LANG_ENG, config=CONFIG_LINE_ENG)
    
    # 3. Number/Date Span (Strict mode)
    if script == "NUM":
        return pytesseract.image_to_string(crop, lang=LANG_ENG, config=CONFIG_DIGITS)
    
    # Fallback
    return pytesseract.image_to_string(crop, lang=f"{LANG_DEV}+{LANG_ENG}", config=CONFIG_GENERAL)


def extract_from_scanned_pdf(pdf_path):
    pages = convert_from_path(pdf_path, dpi=300)
    final_lines_all_pages = []

    for page_no, page in enumerate(pages, 1):
        print(f"Processing Page {page_no}...")
        processed_img = preprocess_image(page)
        h_img, w_img = processed_img.shape
        
        # Initial Pass: Use Mixed Language to find WHERE the words are
        data = pytesseract.image_to_data(
            processed_img, 
            lang=f"{LANG_DEV}+{LANG_ENG}", 
            config=CONFIG_GENERAL, 
            output_type=pytesseract.Output.DICT
        )

        n = len(data["text"])
        lines_words = {}

        # --- Step A: Group words by Line Number ---
        for i in range(n):
            word = data["text"][i].strip()
            if not word:
                continue
            
            # Key = (Block, Paragraph, Line)
            key = (data["block_num"][i], data["par_num"][i], data["line_num"][i])
            
            bbox = (data["left"][i], data["top"][i], data["width"][i], data["height"][i])
            lines_words.setdefault(key, []).append((word, bbox))

        # --- Step B: Process each line left-to-right ---
        for key in sorted(lines_words.keys()):
            words_bboxes = lines_words[key]
            
            # CRITICAL: Sort words by 'left' (x) coordinate to ensure correct reading order
            # This fixes issues where words in mixed lines appear out of order.
            words_bboxes.sort(key=lambda x: x[1][0])
            
            spans = []
            current_script = None
            current_span = []

            for word, bbox in words_bboxes:
                # 1. Detect Script
                raw_script = None
                if DEV_RGX.search(word):
                    raw_script = "DEV"  # Found Hindi char
                elif re.search(r'[A-Za-z]', word):
                    raw_script = "ENG"  # Found English char
                else:
                    raw_script = "OTHER" # Numbers, Punctuation, Symbols

                # 2. "Sticky" Logic for URLs, Emails, and Dates
                # If we see punctuation (@, ., //), we STICK to the current script.
                # This prevents breaking "swapnil@gmail.com" into 3 pieces.
                if raw_script == "OTHER":
                    if current_script:
                        script = current_script
                    else:
                        script = "ENG" # Default to Eng if line starts with punctuation
                else:
                    script = raw_script

                # 3. Numeric Check (Only switch to NUM if it's NOT inside a URL/Email)
                if script == "ENG" and is_numeric_like(word) and not re.search(r'[@//]', word):
                     script = "NUM"

                # 4. Create Spans
                # If script changes, we save the old span and start a new one
                if script != current_script and current_script is not None:
                    spans.append((current_script, current_span))
                    current_span = []

                current_script = script
                current_span.append((word, bbox))

            # Don't forget the last span
            if current_span:
                spans.append((current_script, current_span))

            # --- Step C: Crop and Re-OCR each Span ---
            reconstructed_line_parts = []
            
            for script, span_items in spans:
                # Calculate the bounding box for the entire span (e.g., the whole Hindi sentence part)
                xs = [x for (_, (x, y, w, h)) in span_items]
                ys = [y for (_, (x, y, w, h)) in span_items]
                x_maxs = [x + w for (_, (x, y, w, h)) in span_items]
                y_maxs = [y + h for (_, (x, y, w, h)) in span_items]

                x_min, y_min = min(xs), min(ys)
                x_max, y_max = max(x_maxs), max(y_maxs)

                # Add Padding so Tesseract can see the edges of characters
                pad = 6
                crop = processed_img[
                    max(0, y_min - pad): min(h_img, y_max + pad),
                    max(0, x_min - pad): min(w_img, x_max + pad)
                ]

                # We pass the coarse text just to check for dates
                coarse_text = " ".join([w for w, _ in span_items])
                
                # RE-OCR the specific part with the SPECIFIC language
                raw = ocr_crop(crop, script, coarse_text).strip()
                
                if raw:
                    cleaned = fix_text_general(raw)
                    reconstructed_line_parts.append(cleaned)

            # Join parts with a space to form the final line
            if reconstructed_line_parts:
                full_line = " ".join(reconstructed_line_parts)
                final_lines_all_pages.append(full_line)

    return "\n".join(final_lines_all_pages)


# ---------------------------------------------------------------------------
# 5. MAIN EXECUTION
# ---------------------------------------------------------------------------
if __name__ == "__main__":
    input_folder = r"/home/jupyter-swapnil/OCR/Input"
    output_folder = r"/home/jupyter-swapnil/OCR/Output_Mix"

    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for filename in os.listdir(input_folder):
        if filename.lower().endswith(".pdf"):
            pdf_path = os.path.join(input_folder, filename)
            print(f"Processing: {filename}")
            
            try:
                text_result = extract_from_scanned_pdf(pdf_path)
                
                output_filename = os.path.splitext(filename)[0] + ".txt"
                output_path = os.path.join(output_folder, output_filename)
                
                with open(output_path, "w", encoding="utf-8") as f:
                    f.write(text_result)
                    
                print(f"Saved: {output_filename}")
                
            except Exception as e:
                print(f"Error processing {filename}: {e}")
